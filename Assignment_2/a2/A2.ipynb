{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinyichen/Library/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "# Load the data\n",
    "def loadData():\n",
    "    with np.load(\"notMNIST.npz\") as data:\n",
    "        Data, Target = data[\"images\"], data[\"labels\"]\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data = Data[randIndx] / 255.0\n",
    "        Target = Target[randIndx]\n",
    "        trainData, trainTarget = Data[:10000], Target[:10000]\n",
    "        validData, validTarget = Data[10000:16000], Target[10000:16000]\n",
    "        testData, testTarget = Data[16000:], Target[16000:]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
    "\n",
    "# Implementation of a neural network using only Numpy - trained using gradient descent with momentum\n",
    "\n",
    "\n",
    "def convertOneHot(trainTarget, validTarget, testTarget):\n",
    "    newtrain = np.zeros((trainTarget.shape[0], 10))\n",
    "    newvalid = np.zeros((validTarget.shape[0], 10))\n",
    "    newtest = np.zeros((testTarget.shape[0], 10))\n",
    "\n",
    "    for item in range(0, trainTarget.shape[0]):\n",
    "        newtrain[item][trainTarget[item]] = 1\n",
    "    for item in range(0, validTarget.shape[0]):\n",
    "        newvalid[item][validTarget[item]] = 1\n",
    "    for item in range(0, testTarget.shape[0]):\n",
    "        newtest[item][testTarget[item]] = 1\n",
    "    return newtrain, newvalid, newtest\n",
    "\n",
    "\n",
    "def shuffle(trainData, trainTarget):\n",
    "    np.random.seed(421)\n",
    "    randIndx = np.arange(len(trainData))\n",
    "    target = trainTarget\n",
    "    np.random.shuffle(randIndx)\n",
    "    data, target = trainData[randIndx], target[randIndx]\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    # TODO\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    # TODO\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def computeLayer(X, W, b):\n",
    "    # TODO\n",
    "    return np.matmul(X, W)+b\n",
    "\n",
    "\n",
    "def CE(target, prediction):\n",
    "    # TODO\n",
    "    score = softmax(prediction)\n",
    "    ce = np.sum(np.multiply(target, np.log(score)), axis=1)\n",
    "    loss = -np.mean(ce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradCE(target, prediction):\n",
    "    # TODO\n",
    "    N = target.shape[0]\n",
    "    score = softmax(prediction)\n",
    "    print (\"score.shape: \", score.shape)\n",
    "    print (\"target.shape: \",target.shape)\n",
    "    res = score - prediction\n",
    "    return res\n",
    "\n",
    "\n",
    "def error(target, prediction):\n",
    "    return np.multiply((target-prediction),(target-prediction))\n",
    "\n",
    "\n",
    "def derivation_LW(last_X, y, target):\n",
    "    grad_CE = gradCE(target, y)\n",
    "    res = 2*np.multiply((np.multiply((y-target), grad_CE)), last_X)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "    train_y, valid_y, test_y = convertOneHot(trainTarget, validTarget, testTarget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    s, l, h = trainData.shape #1000 samples, 28, 28\n",
    "    F = l*h  #784 features\n",
    "    c = 10  #10 classes\n",
    "    xi = trainData.reshape(s, F)\n",
    "    variance_h = 2/(F + s)\n",
    "    variance_o = 2/(s + c)\n",
    "\n",
    "    mean, stand_dev_h, stand_dev_o = 0, math.sqrt(variance_h), math.sqrt(variance_o), \n",
    "\n",
    "    Wh = np.random.normal(mean, stand_dev_h, (F, s)) #784,1000\n",
    "    bh = np.zeros((1,s))                           #1, 10\n",
    "    Wo = np.random.normal(mean, stand_dev_o, (s, c)) #1000, 10\n",
    "    bo = np.zeros((1,c))                           #1, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    del_Wh = np.full((F, s), 1e-5)\n",
    "    del_bh = np.full((1, s), 1e-5)\n",
    "    del_Wo = np.full((s, c), 1e-5)\n",
    "    del_bo = np.full((1,c), 1e-5)\n",
    "\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xh's shape:  (10000, 10000)\n",
      "yo's shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "        sh = computeLayer(xi, Wh, bh)\n",
    "        xh = relu(sh)\n",
    "        print (\"xh's shape: \", xh.shape)\n",
    "        so = computeLayer(xh, Wo, bo)\n",
    "        yo = softmax(so)\n",
    "        print (\"yo's shape: \", yo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score.shape:  (10000, 10)\n",
      "target.shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "grad_ce = gradCE(train_y,yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wo = np.dot(xh,grad_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_bo = np.dot(1,grad_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wh = np.dot(grad_ce,np.transpose(Wo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(der_wh.shape)\n",
    "print (sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wh1 = np.where(sh>0,der_wh,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "der_wh = np.dot(der_wh1,xi)\n",
    "print (der_wh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(der_wo.shape)\n",
    "print(der_bo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10000,10000) (10000,10) () ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-b931ab61c7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mder_e_xib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_ce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mder_e_xib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mder_e_xib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#delta_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mder_bh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mder_e_xib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,10000) (10000,10) () "
     ]
    }
   ],
   "source": [
    "    der_e_xib = np.dot(grad_ce,1)\n",
    "    der_e_xib = np.where(sh>0,der_e_xib,0) #delta_h\n",
    "    der_bh = np.dot(1,der_e_xib)\n",
    "    print (der_bh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(xi,sh,xh,so,wo,prediction,target):\n",
    "\n",
    "    grad_ce = gradCE(target,prediction) #delta_o\n",
    "    \n",
    "    der_wo = np.dot(xh,grad_ce)\n",
    "    der_bo = np.dot(1,grad_ce)\n",
    "\n",
    "    der_e_xiw = np.dot(grad_ce,np.transpose(wo))\n",
    "    der_e_xiw = np.where(sh>0,der_e_xiw,0)  #delta_h\n",
    "    der_wh = np.dot(xi,der_e_xiw)\n",
    "\n",
    "    der_e_xib = np.dot(grad_ce,1)\n",
    "    der_e_xib = np.where(sh>0,der_e_xib,0) #delta_h\n",
    "    der_bh = np.dot(1,der_e_xib)\n",
    "\n",
    "    return der_wo, der_bo, der_wh, der_bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(epochs=200):\n",
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "    train_y, valid_y, test_y = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "\n",
    "    print (\"trainTarget.shape: \",trainTarget.shape)\n",
    "    print (\"newtrain.shape: \", train_y.shape)\n",
    "    s, l, h = trainData.shape #1000 samples, 28, 28\n",
    "    F = l*h  #784 features\n",
    "    c = 10  #10 classes\n",
    "    xi = trainData.reshape(s, F)\n",
    "    variance_h = 2/(F + s)\n",
    "    variance_o = 2/(s + c)\n",
    "\n",
    "    mean, stand_dev_h, stand_dev_o = 0, math.sqrt(variance_h), math.sqrt(variance_o), \n",
    "\n",
    "    Wh = np.random.normal(mean, stand_dev_h, (F, s)) #784,1000\n",
    "    bh = np.zeros((1,s))                           #1, 10\n",
    "    Wo = np.random.normal(mean, stand_dev_o, (s, c)) #1000, 10\n",
    "    bo = np.zeros((1,c))                           #1, 10\n",
    "    print (Wh.shape)    \n",
    "    print (bh.shape)\n",
    "    print (Wo.shape)\n",
    "    print (bo.shape)\n",
    "\n",
    "    v_Wh = np.full((F, s), 1e-5)\n",
    "    v_bh = np.full((1, s), 1e-5)\n",
    "    v_Wo = np.full((s, c), 1e-5)\n",
    "    v_bo = np.full((1,c), 1e-5)\n",
    "\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    i = 0\n",
    "    while i < epochs:\n",
    "        # forward propagate\n",
    "\n",
    "        sh = computeLayer(xi, Wh, bh)\n",
    "        xh = relu(sh)\n",
    "        print (\"xh's shape: \", xh.shape)\n",
    "        so = computeLayer(xh, Wo, bo)\n",
    "        yo = softmax(so)\n",
    "        print (\"yo's shape: \", yo.shape)\n",
    "        \n",
    "        print (sh.shape)\n",
    "        print(xh.shape)\n",
    "        print(so.shape)\n",
    "        print(yo.shape)\n",
    "        # backward propagate\n",
    "        der_wo, der_bo, der_wh, der_bh = backPropagation(xi,sh,xh,so,Wo,yo,train_y)\n",
    "\n",
    "        v_Wh = gamma*v_Wh + learning_rate*der_wh\n",
    "        v_bh = gamma*v_bh + learning_rate*der_bh\n",
    "        v_Wo = gamma*v_Wo + learning_rate*der_wo\n",
    "        v_bo = gamma*v_bo + learning_rate*der_bo\n",
    "\n",
    "        Wh = Wh - v_Wh\n",
    "        bh = bh - v_bh\n",
    "        Wo = Wo - v_Wo\n",
    "        bo = bo - v_bo\n",
    "    print(Wo)\n",
    "    print(bo)\n",
    "    print (Wh)\n",
    "    print (bh)\n",
    "    a, b = classify_result(trainData, trainTarget, Wo, bo)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainTarget.shape:  (10000,)\n",
      "newtrain.shape:  (10000, 10)\n",
      "(784, 10000)\n",
      "(1, 10000)\n",
      "(10000, 10)\n",
      "(1, 10)\n",
      "xh's shape:  (10000, 10000)\n",
      "yo's shape:  (10000, 10)\n",
      "(10000, 10000)\n",
      "(10000, 10000)\n",
      "(10000, 10)\n",
      "(10000, 10)\n",
      "score.shape:  (10000, 10)\n",
      "target.shape:  (10000, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,784) and (10000,10000) not aligned: 784 (dim 1) != 10000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6fd1a7e30b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-b435079c766b>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# backward propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mder_wo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mder_bo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mder_wh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mder_bh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mv_Wh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv_Wh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mder_wh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-839ac5d82be5>\u001b[0m in \u001b[0;36mbackPropagation\u001b[0;34m(xi, sh, xh, so, wo, prediction, target)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mder_e_xiw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_ce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mder_e_xiw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mder_e_xiw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#delta_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mder_wh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mder_e_xiw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mder_e_xib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_ce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10000,784) and (10000,10000) not aligned: 784 (dim 1) != 10000 (dim 0)"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
