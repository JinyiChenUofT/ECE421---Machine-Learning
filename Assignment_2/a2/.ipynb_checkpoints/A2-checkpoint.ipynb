{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinyichen/Library/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "# Load the data\n",
    "def loadData():\n",
    "    with np.load(\"notMNIST.npz\") as data:\n",
    "        Data, Target = data[\"images\"], data[\"labels\"]\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data = Data[randIndx] / 255.0\n",
    "        Target = Target[randIndx]\n",
    "        trainData, trainTarget = Data[:10000], Target[:10000]\n",
    "        validData, validTarget = Data[10000:16000], Target[10000:16000]\n",
    "        testData, testTarget = Data[16000:], Target[16000:]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
    "\n",
    "# Implementation of a neural network using only Numpy - trained using gradient descent with momentum\n",
    "\n",
    "\n",
    "def convertOneHot(trainTarget, validTarget, testTarget):\n",
    "    newtrain = np.zeros((trainTarget.shape[0], 10))\n",
    "    newvalid = np.zeros((validTarget.shape[0], 10))\n",
    "    newtest = np.zeros((testTarget.shape[0], 10))\n",
    "\n",
    "    for item in range(0, trainTarget.shape[0]):\n",
    "        newtrain[item][trainTarget[item]] = 1\n",
    "    for item in range(0, validTarget.shape[0]):\n",
    "        newvalid[item][validTarget[item]] = 1\n",
    "    for item in range(0, testTarget.shape[0]):\n",
    "        newtest[item][testTarget[item]] = 1\n",
    "    return newtrain, newvalid, newtest\n",
    "\n",
    "\n",
    "def shuffle(trainData, trainTarget):\n",
    "    np.random.seed(421)\n",
    "    randIndx = np.arange(len(trainData))\n",
    "    target = trainTarget\n",
    "    np.random.shuffle(randIndx)\n",
    "    data, target = trainData[randIndx], target[randIndx]\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    # TODO\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    # TODO\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def computeLayer(X, W, b):\n",
    "    # TODO\n",
    "    return np.matmul(X, W)+b\n",
    "\n",
    "\n",
    "def CE(target, prediction):\n",
    "    # TODO\n",
    "    score = softmax(prediction)\n",
    "    ce = np.sum(np.multiply(target, np.log(score)), axis=1)\n",
    "    loss = -np.mean(ce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def gradCE(target, prediction):\n",
    "    # TODO\n",
    "    N = target.shape[0]\n",
    "    score = softmax(prediction)\n",
    "    print (\"score.shape: \", score.shape)\n",
    "    print (\"target.shape: \",target.shape)\n",
    "    res = score - prediction\n",
    "    return res\n",
    "\n",
    "\n",
    "def error(target, prediction):\n",
    "    return np.multiply((target-prediction),(target-prediction))\n",
    "\n",
    "\n",
    "def derivation_LW(last_X, y, target):\n",
    "    grad_CE = gradCE(target, y)\n",
    "    res = 2*np.multiply((np.multiply((y-target), grad_CE)), last_X)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "    train_y, valid_y, test_y = convertOneHot(trainTarget, validTarget, testTarget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    s, l, h = trainData.shape #1000 samples, 28, 28\n",
    "    F = l*h  #784 features\n",
    "    c = 10  #10 classes\n",
    "    xi = trainData.reshape(s, F)\n",
    "    variance_h = 2/(F + s)\n",
    "    variance_o = 2/(s + c)\n",
    "\n",
    "    mean, stand_dev_h, stand_dev_o = 0, math.sqrt(variance_h), math.sqrt(variance_o), \n",
    "\n",
    "    Wh = np.random.normal(mean, stand_dev_h, (F, s)) #784,1000\n",
    "    bh = np.zeros((1,s))                           #1, 10\n",
    "    Wo = np.random.normal(mean, stand_dev_o, (s, c)) #1000, 10\n",
    "    bo = np.zeros((1,c))                           #1, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    del_Wh = np.full((F, s), 1e-5)\n",
    "    del_bh = np.full((1, s), 1e-5)\n",
    "    del_Wo = np.full((s, c), 1e-5)\n",
    "    del_bo = np.full((1,c), 1e-5)\n",
    "\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xh's shape:  (10000, 10000)\n",
      "yo's shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "        sh = computeLayer(xi, Wh, bh)\n",
    "        xh = relu(sh)\n",
    "        print (\"xh's shape: \", xh.shape)\n",
    "        so = computeLayer(xh, Wo, bo)\n",
    "        yo = softmax(so)\n",
    "        print (\"yo's shape: \", yo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score.shape:  (10000, 10)\n",
      "target.shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "grad_ce = gradCE(train_y,yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wo = np.dot(xh,grad_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_bo = np.dot(1,grad_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wh = np.dot(grad_ce,np.transpose(Wo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(der_wh.shape)\n",
    "print (sh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "der_wh1 = np.where(sh>0,der_wh,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.72030639e-08,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.33761943e-09],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.16707038e-07,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         3.46566745e-08,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.98201867e-08, -1.31618474e-07,  3.22783158e-08],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00, -6.73429272e-08,  6.28130318e-08],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         2.70679905e-09,  0.00000000e+00,  3.39311141e-08]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der_wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04127626,  0.21212242, -0.28328297, ..., -0.02019434,\n",
       "        -0.01616141,  0.19211828],\n",
       "       [-0.10275515, -0.19528012, -0.2012543 , ...,  0.00223937,\n",
       "        -0.07819647, -0.12196877],\n",
       "       [-0.13868235, -0.03568546, -0.16692097, ...,  0.11587752,\n",
       "        -0.23398471, -0.2237074 ],\n",
       "       ...,\n",
       "       [-0.04827196, -0.01571747, -0.32296424, ...,  0.15042049,\n",
       "         0.09571025,  0.36415159],\n",
       "       [-0.13641463, -0.2874804 , -0.14622749, ..., -0.1834559 ,\n",
       "         0.01378742,  0.20048749],\n",
       "       [-0.10550014, -0.09018722, -0.12940096, ...,  0.14237806,\n",
       "        -0.01479827,  0.06382265]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.72030639e-08,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.33761943e-09],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.16707038e-07,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         3.46566745e-08,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.98201867e-08, -1.31618474e-07,  3.22783158e-08],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00, -6.73429272e-08,  6.28130318e-08],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         2.70679905e-09,  0.00000000e+00,  3.39311141e-08]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der_wh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 12],\n",
       "       [ 0, 12,  0],\n",
       "       [ 0, 13,  0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([[ -0.04127626,  -0.04127626,  0.21212242],\n",
    "       [ 0,  2, -1],\n",
    "       [ 0,  3, -1]])\n",
    "b = np.array([[ 10,  11,  12],\n",
    "       [ 10,  12, 11],\n",
    "       [ 10,  13, 11]])\n",
    "np.where(a>0,b,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(epochs=200):\n",
    "    trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "    train_y, valid_y, test_y = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "\n",
    "    print (\"trainTarget.shape: \",trainTarget.shape)\n",
    "    print (\"newtrain.shape: \", train_y.shape)\n",
    "    s, l, h = trainData.shape #1000 samples, 28, 28\n",
    "    F = l*h  #784 features\n",
    "    c = 10  #10 classes\n",
    "    xi = trainData.reshape(s, F)\n",
    "    variance_h = 2/(F + s)\n",
    "    variance_o = 2/(s + c)\n",
    "\n",
    "    mean, stand_dev_h, stand_dev_o = 0, math.sqrt(variance_h), math.sqrt(variance_o), \n",
    "\n",
    "    Wh = np.random.normal(mean, stand_dev_h, (F, s)) #784,1000\n",
    "    bh = np.zeros((1,s))                           #1, 10\n",
    "    Wo = np.random.normal(mean, stand_dev_o, (s, c)) #1000, 10\n",
    "    bo = np.zeros((1,c))                           #1, 10\n",
    "\n",
    "\n",
    "    v_Wh = np.full((F, s), 1e-5)\n",
    "    v_bh = np.full((1, s), 1e-5)\n",
    "    v_Wo = np.full((s, c), 1e-5)\n",
    "    v_bo = np.full((1,c), 1e-5)\n",
    "\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    i = 0\n",
    "    while i < epochs:\n",
    "        # forward propagate\n",
    "\n",
    "        sh = computeLayer(xi, Wh, bh)\n",
    "        xh = relu(sh)\n",
    "        print (\"xh's shape: \", xh.shape)\n",
    "        so = computeLayer(xh, Wo, bo)\n",
    "        yo = softmax(so)\n",
    "        print (\"yo's shape: \", yo.shape)\n",
    "\n",
    "        # backward propagate\n",
    "        der_wo, der_bo, der_wh, der_bh = backPropagation(xi,sh,xh,so,Wo,yo,train_y)\n",
    "\n",
    "        v_Wh = gamma*v_Wh + learning_rate*der_wh\n",
    "        v_bh = gamma*v_bh + learning_rate*der_bh\n",
    "        v_Wo = gamma*v_Wo + learning_rate*der_wo\n",
    "        v_bo = gamma*v_bo + learning_rate*der_bo\n",
    "\n",
    "        Wh = Wh - v_Wh\n",
    "        bh = bh - v_bh\n",
    "        Wo = Wo - v_Wo\n",
    "        bo = bo - v_bo\n",
    "    print(Wo)\n",
    "    print(bo)\n",
    "    print (Wh)\n",
    "    print (bh)\n",
    "    a, b = classify_result(trainData, trainTarget, Wo, bo)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
